{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Hypers --------\n",
      "- epochs: 50\n",
      "- learning rate: 0.5\n",
      "- hidden size: 100\n",
      "----------------\n",
      "\n",
      "Epoch 1/50\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /opt/conda/conda-bld/pytorch_1544174967633/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:191",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a3b66bc907c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mmodel_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-a3b66bc907c4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(learning_rate, hidden_size, device)\u001b[0m\n\u001b[1;32m    268\u001b[0m     train_model(model, criterion, optimizer, dataloaders,\n\u001b[1;32m    269\u001b[0m                 \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 best_loss=10, device=device)\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-a3b66bc907c4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataloaders, num_epochs, best_loss, evaluate, device)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m# regular stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;31m# squeeze the unnecessary batchsize dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/28/828/shgao/seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_encoder, input_decoder)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# input_encoder : vector of index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/28/828/shgao/Encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# dimension: word_size x emb_dim -> word_size * emb_dim x 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# output.size = number of features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m         return F.embedding(\n\u001b[1;32m    117\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /opt/conda/conda-bld/pytorch_1544174967633/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:191"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from seq2seq import seq2seq\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "import pickle\n",
    "import SBT_encode\n",
    "import re\n",
    "\n",
    "\n",
    "class Evaluation():\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.loss = .0\n",
    "        self.count_data = 0\n",
    "        self.count_save = 0\n",
    "        self.count_chunk = 0\n",
    "        self.history = {}\n",
    "\n",
    "    def reset(self, epoch):\n",
    "        self.epoch = epoch\n",
    "        self.loss = .0\n",
    "        self.count_data = 0\n",
    "        self.count_save = 0\n",
    "        self.count_chunk = 0\n",
    "        self.history[epoch] = []\n",
    "\n",
    "    def __call__(self, loss, outputs):\n",
    "        loss_ = loss.cpu().detach().numpy()\n",
    "        outputs_ = outputs.cpu().detach().numpy().squeeze()\n",
    "        chunk_size = outputs_.shape[0]\n",
    "        self.loss += loss_ * chunk_size\n",
    "        self.count_data += chunk_size\n",
    "        self.count_chunk += 1\n",
    "\n",
    "    def avg_loss(self):\n",
    "        return self.loss / self.count_data\n",
    "\n",
    "    def save(self, train_loss, val_loss):\n",
    "        self.count_save += 1\n",
    "        self.history[self.epoch].append((train_loss, val_loss))\n",
    "\n",
    "\n",
    "def preprocessing(file_name):\n",
    "    # load data\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    comment = []\n",
    "    code = []\n",
    "    for i in range(len(data)):\n",
    "        temp_comment, temp_code = data[i]\n",
    "        comment.append(temp_comment)\n",
    "        code.append(temp_code)\n",
    "    \n",
    "    set_word = set()\n",
    "    pattern = r',|\\.|/|;|\\'|`|\\[|\\]|<|>|\\?|:|\"|\\{|\\}|\\~|!|@|#|\\$|%|\\^|&|\\(|\\)|-|=|\\_|\\+|，|。|、|；|‘|’|【|】|·|！| |…|（|）'\n",
    "    for i in range(len(comment)):\n",
    "        temp_list = re.split(pattern, comment[i])\n",
    "        for x in temp_list:\n",
    "            set_word.add(x)\n",
    "    commment_wordlist = list(set_word)\n",
    "    comment_dict = dict(zip(commment_wordlist, range(len(commment_wordlist))))\n",
    "    \n",
    "    #print(comment_dict)\n",
    "\n",
    "    encoder = SBT_encode.Encoder()\n",
    "\n",
    "    code_in_num = []\n",
    "    comment_in_num = []\n",
    "\n",
    "    for i in range(len(code)):\n",
    "        code_in_num.append(encoder.encode(code[i]))\n",
    "\n",
    "    for i in range(len(comment)):\n",
    "        split_list = re.split(pattern, comment[i])\n",
    "        temp_list = []\n",
    "        for x in split_list:\n",
    "            temp_list.append(comment_dict[x])\n",
    "        comment_in_num.append(temp_list)\n",
    "\n",
    "    max_len_code = max([len(code_in_num[i]) for i in range(len(code_in_num))])\n",
    "    max_len_comment = max([len(comment_in_num[i]) for i in range(len(comment_in_num))])\n",
    "    \n",
    "#     print(\"Max length of code: \" + str(max_len_code))\n",
    "#     print(\"Max length of comment: \" + str(max_len_comment))\n",
    "\n",
    "    for i in range(len(code_in_num)):\n",
    "        while len(code_in_num[i]) < max_len_code:\n",
    "            code_in_num[i].append(0)\n",
    "\n",
    "    for i in range(len(comment_in_num)):\n",
    "        while len(comment_in_num[i]) < max_len_comment:\n",
    "            comment_in_num[i].append(0)\n",
    "\n",
    "    return code_in_num, comment_in_num, max_len_code, max_len_comment\n",
    "\n",
    "\n",
    "def build_model(word_size_encoder, word_size_decoder, emb_dim=10, hidden_size=100, learning_rate=0.1, device=None):\n",
    "    model = seq2seq(word_size_encoder, emb_dim, hidden_size, word_size_decoder)\n",
    "    # run on the gpu or cpu\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataloaders,\n",
    "                num_epochs=1, best_loss=10,\n",
    "                evaluate=Evaluation(), device=None):\n",
    "    # init timer\n",
    "    since = time.time()\n",
    "    start_epoch = evaluate.epoch\n",
    "    step = 500\n",
    "    # if istest: step = 10\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        print('\\nEpoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        ## reset evaluator in a new epoch\n",
    "        evaluate.reset(epoch)\n",
    "\n",
    "        for i in range(len(dataloaders['train'][0])):\n",
    "\n",
    "            # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "            #inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            inputs, targets = dataloaders['train'][0][i], dataloaders['train'][1][i]\n",
    "            inputs = torch.LongTensor(inputs)\n",
    "            targets = torch.LongTensor(targets)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            # regular stuff\n",
    "            outputs = model(inputs, targets)\n",
    "            # squeeze the unnecessary batchsize dim\n",
    "            loss = criterion(outputs, targets.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # evaluation\n",
    "            evaluate(loss, outputs)\n",
    "\n",
    "            # validate every n chunks\n",
    "            if i % step == 0:\n",
    "                train_loss = evaluate.avg_loss()\n",
    "                # validate first\n",
    "                val_loss = validate_model(model, criterion,\n",
    "                                          dataloaders['val'],\n",
    "                                          device=device)\n",
    "\n",
    "                # update best loss\n",
    "                is_best = val_loss < best_loss\n",
    "                best_loss = min(val_loss, best_loss)\n",
    "\n",
    "                # verbose\n",
    "                print('[%i] '\n",
    "                      'train-loss: %.4f '\n",
    "                      'val-loss: %.4f '\n",
    "                      '' % (evaluate.count_save,\n",
    "                            train_loss,\n",
    "                            val_loss))\n",
    "\n",
    "                # save for plot\n",
    "                evaluate.save(train_loss, val_loss)\n",
    "                save_checkpoint({'model': model.state_dict(),\n",
    "                                 'optimizer': optimizer.state_dict(),\n",
    "                                 'best_loss': best_loss,\n",
    "                                 'history': evaluate}, is_best)\n",
    "\n",
    "            # if istest:\n",
    "            #     if i == 100: break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('\\nTraining complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "# could also be use to test\n",
    "def validate_model(model, criterion, loader, device=None, verbose=False):\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "    evaluate = Evaluation()\n",
    "    step = 50\n",
    "    # if istest: step = 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(loader[0])):\n",
    "            # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "            inputs, targets = loader[0][i], loader[1][i]\n",
    "            inputs = torch.LongTensor(inputs)\n",
    "            targets = torch.LongTensor(targets)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs, targets)\n",
    "            loss = criterion(outputs, targets.squeeze())\n",
    "            evaluate(loss, outputs)\n",
    "\n",
    "            if verbose:\n",
    "                if j % step == 0:\n",
    "                    print('[%i] val-loss: %.4f' % (j, evaluate.avg_loss()))\n",
    "\n",
    "            # if istest:\n",
    "            #     if j == 2: break\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    return evaluate.avg_loss()\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best):\n",
    "    filename = 'checkpoint' + str(model_num) + '.pth.tar'\n",
    "    bestname = 'model_best' + str(model_num) + '.pth.tar'\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, bestname)\n",
    "\n",
    "\n",
    "def check_cuda():\n",
    "    # Check if your system supports CUDA\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    # Setup GPU optimization if CUDA is supported\n",
    "    if use_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "        extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    else:  # Otherwise, train on the CPU\n",
    "        device = torch.device(\"cpu\")\n",
    "        extras = False\n",
    "    return use_cuda, device, extras\n",
    "\n",
    "\n",
    "def main(learning_rate=0.01, hidden_size=100, device=None):\n",
    "    # hyperparameters\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.5\n",
    "    # hidden_size = 100\n",
    "\n",
    "    print('------- Hypers --------\\n'\n",
    "          '- epochs: %i\\n'\n",
    "          '- learning rate: %g\\n'\n",
    "          '- hidden size: %i\\n'\n",
    "          '----------------'\n",
    "          '' % (num_epochs, learning_rate, hidden_size))\n",
    "\n",
    "    train_code_in_num, train_comment_in_num, train_word_size_encoder, train_word_size_decoder = preprocessing('data/train.pkl')\n",
    "    val_code_in_num, val_comment_in_num, val_word_size_encoder, val_word_size_decoder = preprocessing('data/valid.pkl')\n",
    "    test_code_in_num, test_comment_in_num, test_word_size_encoder, test_word_size_decoder = preprocessing('data/test.pkl')\n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = (train_code_in_num, train_comment_in_num)\n",
    "    dataloaders['val'] = (val_code_in_num, val_comment_in_num)\n",
    "    dataloaders['test'] = (test_code_in_num, test_comment_in_num)\n",
    "\n",
    "    # save loader and encoder for later use\n",
    "    # torch.save({'loaders': dataloaders,\n",
    "    #             'encoder': encoder,\n",
    "    #             'hidden_size': hidden_size},\n",
    "    #            'init' + str(model_num) + '.pth.tar')\n",
    "\n",
    "    model, criterion, optimizer = build_model(train_word_size_encoder, train_word_size_decoder,\n",
    "                                              emb_dim=10, hidden_size=100, learning_rate=0.1, device=None)\n",
    "    evaluate = Evaluation()\n",
    "\n",
    "    train_model(model, criterion, optimizer, dataloaders,\n",
    "                num_epochs=num_epochs, evaluate=evaluate,\n",
    "                best_loss=10, device=device)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_num = 0\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
